---
title: "Parallel Test"
author: "Sarah Gaichas"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Test parallel script with [Scenarios](https://noaa-edab.github.io/WHAMmse_longlived/Scenarios.html)

See Cheng's example https://lichengxue.github.io/whamMSE/05.Parallel-Computing.html

First set up the base model, all the way up to the blank mods list, but not sampling data yet

```{r base setup 3yr}
library(wham)
library(whamMSE)

main.dir = here::here()

# get median DOY for each seasonal survey
# from a local surdat pull 
# survdat_nobio <- readRDS(here::here("localhugefiles/survdat_nolength.rds"))
# fracyr <- survdat_nobio$survdat |> #file from April 2025
#   dplyr::mutate(DOY = lubridate::yday(EST_TOWDATE)) |>
#   dplyr::select(SEASON, DOY) |> dplyr::distinct() |>
#   dplyr::group_by(SEASON) |>
#   dplyr::summarise(medDOY = median(DOY, na.rm=T),
#                    fracyrmed = medDOY/365)
# fracyr
# # A tibble: 2 Ã— 3
#   SEASON medDOY fracyrmed
#   <chr>   <dbl>     <dbl>
# 1 FALL     296.     0.812
# 2 SPRING   108.     0.295

year_start  <- 1  # starting year in the burn-in period
year_end    <- 30  # end year in the burn-in period
MSE_years   <- 30     # number of years in the feedback loop
# Note: no need to include MSE_years in simulation-estimation 

info <- generate_basic_info(n_stocks = 1, 
                            n_regions = 1, 
                            n_indices = 2, # spring and fall
                            n_fleets = 1, 
                            n_seasons = 1, # don't need seasons
                            base.years = year_start:year_end,
                            n_feedback_years = MSE_years,
                            life_history = "long",
                            n_ages = 20,
                            # We want a bit higher F in the historical period
                            F_info = list(F.year1 = 0.1, Fhist = "F-H-L", Fmax = 2.5, Fmin = 1, change_time = 0.5, user_F = NULL),
                            catch_info = list(catch_cv = 0.1, catch_Neff = 100),
                            index_info = list(index_cv = 0.3, index_Neff = 100, fracyr_indices = c(0.295, 0.812), q = 0.2),
                            fracyr_spawn = 0.625)

# --------------------------------------------------- #
# ------- Do we need to change fracyr_spawn? -------- #
#    Fraction of the year when spawning is now 0.625  #
# --------------------------------------------------- #

basic_info = info$basic_info # collect basic information
catch_info = info$catch_info # collect fleet catch information
index_info = info$index_info # collect survey information
F_info = info$F # collect fishing information

basic_info <- generate_NAA_where(basic_info = basic_info, move.type = 3) # no movement

move <- NULL

n_stocks  <- as.integer(basic_info['n_stocks'])
n_regions <- as.integer(basic_info['n_regions'])
n_fleets  <- as.integer(basic_info['n_fleets'])
n_indices <- as.integer(basic_info['n_indices'])
n_ages    <- as.integer(basic_info['n_ages'])

# Selectivity Configuration
# for logistic pars are a50 and 1/slope
# approximate from redfish model
fleet_pars <- c(9,1)
index_pars <- list(c(5,1), c(3,1))
sel <- list(model=rep("logistic",n_fleets+n_indices),
            initial_pars=c(rep(list(fleet_pars),n_fleets),
                           #rep(list(index_pars),n_indices)))
                           index_pars))

# redfish M is 0.05 but I'll leave this at 0.1 
# M Configuration
M <- list(model="constant",initial_means=array(0.1, dim = c(n_stocks,n_regions,n_ages)))

sigma      <- "rec+1"
re_cor     <- "iid"
ini.opt    <- "equilibrium" # option   <- c("age-specific-fe", "equilibrium")

# # Set para. for B-H function, not using
# alpha <- 12
# beta  <- 1.5e-4

# Set sigma for NAA
# add higher rec_sig similar to redfish WHAM
Rec_sig <- 1.0
NAA_sig <- 0.2
sigma_vals = array(NAA_sig, dim = c(n_stocks, n_regions, n_ages)) # n_stocks x n_regions x n_ages"
sigma_vals[,,1] = Rec_sig

# Set initial NAA for each stock
log_N1  <- rep(10, n_stocks) # Create difference between stocks

# ------------------------------------------------------ #
# ------------- Below code has been changed ------------ #
# ------------------------------------------------------ #

N1_pars <- generate_ini_N1(basic_info = basic_info, ini.opt = "equilibrium", log_N1 = log_N1, log_N1_F = 0.1)
# WE MAY NEED TO HAVE A MORE SENSIBLE INITIAL NUMBERS AT AGE (now is using default: Number of age 1 = exp(10))

# ------------------------------------------------------ #
# ------------- Above code has been changed ------------ #
# ------------------------------------------------------ #

# Set mean recruitment para. for each stock
mean_rec_par <- list()
for (i in 1:n_stocks) mean_rec_par[[i]] <- exp(log_N1[i]) #

# ------------------------------------------------------ #
# ------ WE MAY NEED A SENSIBLE MEAN RECREUITMENT ------ #
# ------------------------------------------------------ #

NAA_re <- list(N1_model=rep(ini.opt,n_stocks),
               sigma=rep(sigma,n_stocks),
               cor=rep(re_cor,n_stocks),
               recruit_model = 2,
               recruit_pars = mean_rec_par, # rep(list(c(alpha,beta)),n_stocks), # assume same B-H s-r functions for all stocks
               sigma_vals = sigma_vals,
               N1_pars = N1_pars)#,
               #NAA_where = basic_info$NAA_where)

# recruit_model = 1: estimating annual recruitments as fixed effects or a random walk if NAA_re$sigma specified
# recruit_model = 2: estimating a mean recruitment with annual recruitments as random effects
# recruit_model = 3: Beverton-Holt stock-recruitment with annual recruitments as random effects
# recruit_model = 4: Ricker stock-recruitment with annual recruitments as random effects

# 1. recruit_pars: a list (length = n_stocks) of vectors of initial parameters for recruitment model. 
# If $recruit_model is 3 (B-H) or 4 (Ricker), parameters are "alpha" and "beta".

# 2. sigma_vals: Initial standard deviation values to use for the NAA deviations. Values are not used if recruit_model = 1 
# If sigma="rec": must be a list (length = n_stocks) of single values
# If sigma="rec+1": a list (length = n_stocks) of 2 values must be specified. First is for the first age class (recruits), second is for all other ages.


input <- prepare_wham_input(basic_info = basic_info, 
                            selectivity = sel, 
                            M = M, 
                            NAA_re = NAA_re, 
                            move = move,
                            catch_info = catch_info, 
                            index_info = index_info, 
                            F = F_info)

# IMPORTANT!#
# This appears to be due to the initial F value for the Newton iterations to find F40. The default value is too high for long-lived fish
input$data$FXSPR_init[] <- 0.01 # change to a low value

# -------------------
# IMPORTANT!#
# -------------------
# Change initial numbers at age in the input for OM
# ini.NAA <- matrix(NA, n_ages, n_stocks)
# ini.NAA[,1] <- c(20:1) # Use actually initial numbers at age from assessment model?
# 
# input$par$log_N1[] = 0
# for (i in 1:n_regions) {
#   input$par$log_N1[i,i,] = log(ini.NAA[,i])
# }

random = input$random # check what processes are random effects
input$random = NULL # so inner optimization won't change simulated RE
om <- fit_wham(input, do.fit = F, do.brps = T, MakeADFun.silent = TRUE)
# Note: do.fit must be FALSE (no modeling fitting yet)

#om_with_data <- update_om_fn(om, seed = 123, random = random)

assess.interval <- 3 # 
base.years      <- year_start:year_end # Burn-in period
first.year      <- head(base.years,1)
terminal.year   <- tail(base.years,1)
assess.years    <- seq(terminal.year, tail(om$years,1)-assess.interval,by = assess.interval)

mods <- list() # Create a list to save MSE outputs

```

Set up folders for results

```{r, eval=FALSE}
sub.dir = "Results_test"
dir.create(file.path(getwd(), sub.dir), recursive = TRUE)

library(doParallel)
library(foreach)

detectCores() # check how many cores available
```


Set up clusters to run multiple sims for each scenario

```{r}
cluster <- makeCluster(5) 
registerDoParallel(cluster)

foreach (i = 1:5) %dopar% {
  
  library(wham)
  library(whamMSE)
  
  om_with_data <- update_om_fn(om, seed = 123+i, random = random)
  
  NAA_re_em <- list(N1_model="equilibrium",sigma="rec+1",cor="iid")

  mod = loop_through_fn(om = om_with_data,
                            em_info = info, 
                            random = random,
                            M_em = M, # use OM M
                            sel_em = sel, # use OM sel
                            NAA_re_em = NAA_re_em, # use rec assumed random around the mean instead, help runtime (est B-H is difficult)
                            move_em = NULL,
                            age_comp_em = "multinomial",
                            # Here is the correct code: separate.em = FALSE also works for one-area model
                            em.opt = list(separate.em = FALSE, separate.em.type = 1, 
                                          do.move = FALSE, est.move = FALSE),
                            assess_years = assess.years, 
                            assess_interval = assess.interval, 
                            base_years = base.years,
                            year.use = 30, # number of years of data you want to use in the assessment model
                            add.years = TRUE, # extends assessment time series instead of moving window of year.use years
                            seed = 123+i,
                            save.sdrep = FALSE, 
                            save.last.em = TRUE,
                            FXSPR_init = 0.01) # IMPORTANT!

  
  saveRDS(mod, file.path(sub.dir,sprintf("Mod1_%03d.RDS",i)))
  
}

stopCluster(cluster)

```

Now try the same thing (base case) changing the assessment frequency

```{r}
assess.interval <- 6 # 

base.years      <- year_start:year_end # Burn-in period
first.year      <- head(base.years,1)
terminal.year   <- tail(base.years,1)
assess.years    <- seq(terminal.year, tail(om$years,1)-assess.interval,by = assess.interval)


cluster <- makeCluster(5) 
registerDoParallel(cluster)

foreach (i = 1:5) %dopar% {
  
  library(wham)
  library(whamMSE)
  
  om_with_data <- update_om_fn(om, seed = 123+i, random = random)
  
  NAA_re_em <- list(N1_model="equilibrium",sigma="rec+1",cor="iid")

  mod = loop_through_fn(om = om_with_data,
                            em_info = info, 
                            random = random,
                            M_em = M, # use OM M
                            sel_em = sel, # use OM sel
                            NAA_re_em = NAA_re_em, # use rec assumed random around the mean instead, help runtime (est B-H is difficult)
                            move_em = NULL,
                            age_comp_em = "multinomial",
                            # Here is the correct code: separate.em = FALSE also works for one-area model
                            em.opt = list(separate.em = FALSE, separate.em.type = 1, 
                                          do.move = FALSE, est.move = FALSE),
                            assess_years = assess.years, 
                            assess_interval = assess.interval, 
                            base_years = base.years,
                            year.use = 30, # number of years of data you want to use in the assessment model
                            add.years = TRUE, # extends assessment time series instead of moving window of year.use years
                            seed = 123+i,
                            save.sdrep = FALSE, 
                            save.last.em = TRUE,
                            FXSPR_init = 0.01) # IMPORTANT!

  
  saveRDS(mod, file.path(sub.dir,sprintf("Mod2_%03d.RDS",i)))
  
}

stopCluster(cluster)
```

Try the low data example that worked individually, first the setup

```{r}
agg_index_sigma = input$data$agg_index_sigma
agg_index_sigma[31:60,] = 0.6 # Increase CV for both survey indices in the feedback period
index_Neff = input$data$index_Neff
index_Neff[31:60,] = 50 # Decrease ESS for both survey indices in the feedback period

#alternate years fall and spring surveys
remove_agg = TRUE # remove a aggregate index for some years
remove_agg_pointer = c(1,2) # both
remove_agg_years = matrix(data=c(seq(31,60,2), seq(32,60,2)), nrow=15, ncol=2) #alternating years by survey
remove_paa = TRUE # Also remove age comp for that index 
remove_paa_pointer = c(1,2) # both
remove_paa_years = matrix(data=c(seq(31,60,2), seq(32,60,2)), nrow=15, ncol=2) #alternating years by survey

input <- update_input_index_info(input, agg_index_sigma, index_Neff,
                                 remove_agg, remove_agg_pointer, remove_agg_years,
                                 remove_paa, remove_paa_pointer, remove_paa_years) # Update input file

agg_catch_sigma = input$data$agg_catch_sigma
agg_catch_sigma[31:60,] = 0.2 #double catch CV in the feedback period
catch_Neff = input$data$catch_Neff
catch_Neff[31:60] = 50

input <- update_input_catch_info(input, agg_catch_sigma, catch_Neff)

om <- fit_wham(input, do.fit = F, do.brps = T, MakeADFun.silent = TRUE)

```

Now run in parallel, 3 year assessment

```{r}
assess.interval <- 3 # 

base.years      <- year_start:year_end # Burn-in period
first.year      <- head(base.years,1)
terminal.year   <- tail(base.years,1)
assess.years    <- seq(terminal.year, tail(om$years,1)-assess.interval,by = assess.interval)

cluster <- makeCluster(5) 
registerDoParallel(cluster)

foreach (i = 1:5) %dopar% {
  
  library(wham)
  library(whamMSE)
  
  om_with_data <- update_om_fn(om, seed = 123+i, random = random)
  
  NAA_re_em <- list(N1_model="equilibrium",sigma="rec+1",cor="iid")

  mod = loop_through_fn(om = om_with_data,
                            em_info = info, 
                            random = random,
                            M_em = M, # use OM M
                            sel_em = sel, # use OM sel
                            NAA_re_em = NAA_re_em, # use rec assumed random around the mean instead, help runtime (est B-H is difficult)
                            move_em = NULL,
                            age_comp_em = "multinomial",
                            # Here is the correct code: separate.em = FALSE also works for one-area model
                            em.opt = list(separate.em = FALSE, separate.em.type = 1, 
                                          do.move = FALSE, est.move = FALSE),
                            # ------------------------------------------------------ #
                            # - Below is needed when making changes on data quality- #
                            # ------------------------------------------------------ #
                            update_index_info  = list(agg_index_sigma = agg_index_sigma, index_Neff = index_Neff), # Must have this!
                            update_catch_info  = list(agg_catch_sigma = agg_catch_sigma, catch_Neff = catch_Neff), # Must have this!
                            # ------------------------------------------------------ #
                            # - Above is needed when making changes on data quality- #
                            # ------------------------------------------------------ #
                            assess_years = assess.years, 
                            assess_interval = assess.interval, 
                            base_years = base.years,
                            year.use = 30, # number of years of data you want to use in the assessment model
                            add.years = TRUE, # extends assessment time series instead of moving window of year.use years
                            seed = 123+i,
                            save.sdrep = FALSE, 
                            save.last.em = TRUE,
                            FXSPR_init = 0.01) # IMPORTANT!

  
  saveRDS(mod, file.path(sub.dir,sprintf("Mod3_%03d.RDS",i)))
  
}

stopCluster(cluster)


```

And degraded data with a 6 year assessment

```{r}
assess.interval <- 6 # 

base.years      <- year_start:year_end # Burn-in period
first.year      <- head(base.years,1)
terminal.year   <- tail(base.years,1)
assess.years    <- seq(terminal.year, tail(om$years,1)-assess.interval,by = assess.interval)

cluster <- makeCluster(5) 
registerDoParallel(cluster)

foreach (i = 1:5) %dopar% {
  
  library(wham)
  library(whamMSE)
  
  om_with_data <- update_om_fn(om, seed = 123+i, random = random)
  
  NAA_re_em <- list(N1_model="equilibrium",sigma="rec+1",cor="iid")

  mod = loop_through_fn(om = om_with_data,
                            em_info = info, 
                            random = random,
                            M_em = M, # use OM M
                            sel_em = sel, # use OM sel
                            NAA_re_em = NAA_re_em, # use rec assumed random around the mean instead, help runtime (est B-H is difficult)
                            move_em = NULL,
                            age_comp_em = "multinomial",
                            # Here is the correct code: separate.em = FALSE also works for one-area model
                            em.opt = list(separate.em = FALSE, separate.em.type = 1, 
                                          do.move = FALSE, est.move = FALSE),
                            # ------------------------------------------------------ #
                            # - Below is needed when making changes on data quality- #
                            # ------------------------------------------------------ #
                            update_index_info  = list(agg_index_sigma = agg_index_sigma, index_Neff = index_Neff), # Must have this!
                            update_catch_info  = list(agg_catch_sigma = agg_catch_sigma, catch_Neff = catch_Neff), # Must have this!
                            # ------------------------------------------------------ #
                            # - Above is needed when making changes on data quality- #
                            # ------------------------------------------------------ #
                            assess_years = assess.years, 
                            assess_interval = assess.interval, 
                            base_years = base.years,
                            year.use = 30, # number of years of data you want to use in the assessment model
                            add.years = TRUE, # extends assessment time series instead of moving window of year.use years
                            seed = 123+i,
                            save.sdrep = FALSE, 
                            save.last.em = TRUE,
                            FXSPR_init = 0.01) # IMPORTANT!

  
  saveRDS(mod, file.path(sub.dir,sprintf("Mod4_%03d.RDS",i)))
  
}

stopCluster(cluster)


```

